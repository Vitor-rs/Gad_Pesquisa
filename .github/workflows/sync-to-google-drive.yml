name: Bidirectional Sync GitHub ‚Üî Google Drive

on:
  push:
    branches: [ main, master ]
  schedule:
    # Executar a cada 15 minutos para detectar mudan√ßas no Drive
    - cron: '*/15 * * * *'
  workflow_dispatch:

jobs:
  sync-bidirectional:
    runs-on: ubuntu-latest
    
    # Pula apenas se o commit anterior foi feito pelo pr√≥prio bot de sincroniza√ß√£o
    if: |
      github.event_name == 'schedule' || 
      github.event_name == 'workflow_dispatch' ||
      (github.event_name == 'push' && !contains(github.event.head_commit.message, '[sync-bot]'))
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Bidirectional Sync
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        pip install google-api-python-client google-auth google-auth-oauthlib google-auth-httplib2 requests python-dateutil
        
        python << 'EOF'
        import os
        import sys
        import json
        import hashlib
        import requests
        import subprocess
        from datetime import datetime, timezone
        from dateutil import parser
        from pathlib import Path
        from googleapiclient.discovery import build
        from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload
        from google.oauth2.credentials import Credentials
        import io
        import time
        
        print("üîÑ SINCRONIZA√á√ÉO BIDIRECIONAL GITHUB ‚Üî GOOGLE DRIVE")
        print("=" * 60)
        
        # Configura√ß√µes
        repo_name = 'Gad_Pesquisa'
        branch = 'main'
        folder_id = '${{ secrets.GOOGLE_DRIVE_FOLDER_ID }}'
        github_username = 'Vitor-rs'
        github_email = 'vitor.santos9@estudante.ifms.edu.br'
        
        # Credenciais OAuth2
        client_id = '${{ secrets.GOOGLE_CLIENT_ID }}'
        client_secret = '${{ secrets.GOOGLE_CLIENT_SECRET }}'
        refresh_token = '${{ secrets.GOOGLE_REFRESH_TOKEN }}'
        
        # Arquivos de controle
        SYNC_STATE_FILE = '.sync_state.json'
        SYNC_HISTORY_FILE = '_SYNC_HISTORY.md'
        
        # Verificar credenciais
        missing_secrets = []
        if not client_id: missing_secrets.append('GOOGLE_CLIENT_ID')
        if not client_secret: missing_secrets.append('GOOGLE_CLIENT_SECRET')
        if not refresh_token: missing_secrets.append('GOOGLE_REFRESH_TOKEN')
        if not folder_id: missing_secrets.append('GOOGLE_DRIVE_FOLDER_ID')
        
        if missing_secrets:
            print(f"‚ùå ERRO: Secrets n√£o configurados: {', '.join(missing_secrets)}")
            sys.exit(1)
        
        # Renovar access token
        print("üîÑ Renovando access token...")
        token_url = "https://oauth2.googleapis.com/token"
        token_data = {
            'client_id': client_id,
            'client_secret': client_secret,
            'refresh_token': refresh_token,
            'grant_type': 'refresh_token'
        }
        
        response = requests.post(token_url, data=token_data)
        if response.status_code != 200:
            print(f"‚ùå Erro ao renovar token: {response.text}")
            sys.exit(1)
        
        access_token = response.json()['access_token']
        print("‚úÖ Token renovado com sucesso!")
        
        # Criar credenciais e servi√ßo
        credentials = Credentials(
            token=access_token,
            refresh_token=refresh_token,
            token_uri="https://oauth2.googleapis.com/token",
            client_id=client_id,
            client_secret=client_secret,
            scopes=['https://www.googleapis.com/auth/drive']
        )
        
        service = build('drive', 'v3', credentials=credentials)
        
        # Fun√ß√µes auxiliares
        def calculate_file_hash(file_path):
            """Calcula hash MD5 de um arquivo"""
            hash_md5 = hashlib.md5()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        
        def get_drive_file_hash(file_id):
            """Obt√©m hash MD5 de um arquivo no Drive"""
            try:
                file_metadata = service.files().get(fileId=file_id, fields='md5Checksum').execute()
                return file_metadata.get('md5Checksum', '')
            except:
                return ''
        
        def load_sync_state():
            """Carrega estado anterior da sincroniza√ß√£o"""
            if os.path.exists(SYNC_STATE_FILE):
                with open(SYNC_STATE_FILE, 'r') as f:
                    return json.load(f)
            return {'files': {}, 'last_sync': None}
        
        def save_sync_state(state):
            """Salva estado atual da sincroniza√ß√£o"""
            state['last_sync'] = datetime.now(timezone.utc).isoformat()
            with open(SYNC_STATE_FILE, 'w') as f:
                json.dump(state, f, indent=2)
        
        def should_ignore_file(file_path):
            """Verifica se arquivo deve ser ignorado"""
            ignore_patterns = [
                '.git/', '__pycache__/', 'node_modules/', '.github/',
                '.DS_Store', 'Thumbs.db', '~$', '.tmp', '.cache',
                SYNC_STATE_FILE, '.sync.lock'
            ]
            return any(pattern in str(file_path) for pattern in ignore_patterns)
        
        def get_local_files():
            """Obt√©m lista de arquivos locais com hashes"""
            local_files = {}
            for path in Path('.').rglob('*'):
                if path.is_file() and not should_ignore_file(path):
                    rel_path = str(path).replace('\\', '/')
                    local_files[rel_path] = {
                        'path': rel_path,
                        'hash': calculate_file_hash(path),
                        'size': path.stat().st_size,
                        'modified': datetime.fromtimestamp(path.stat().st_mtime, timezone.utc).isoformat()
                    }
            return local_files
        
        def get_drive_files(parent_id, path=''):
            """Obt√©m lista de arquivos do Drive recursivamente"""
            drive_files = {}
            
            # Listar arquivos
            query = f"'{parent_id}' in parents and trashed=false"
            results = service.files().list(
                q=query,
                fields='files(id, name, mimeType, md5Checksum, size, modifiedTime)',
                pageSize=1000
            ).execute()
            
            for file in results.get('files', []):
                if file['mimeType'] == 'application/vnd.google-apps.folder':
                    # Recursivamente processar subpastas
                    subfolder_path = f"{path}/{file['name']}" if path else file['name']
                    drive_files.update(get_drive_files(file['id'], subfolder_path))
                else:
                    # Ignorar Google Docs nativos
                    if file['mimeType'].startswith('application/vnd.google-apps'):
                        continue
                    
                    file_path = f"{path}/{file['name']}" if path else file['name']
                    if not should_ignore_file(file_path):
                        drive_files[file_path] = {
                            'id': file['id'],
                            'path': file_path,
                            'hash': file.get('md5Checksum', ''),
                            'size': int(file.get('size', 0)),
                            'modified': file.get('modifiedTime', '')
                        }
            
            return drive_files
        
        def download_from_drive(file_id, local_path):
            """Baixa arquivo do Drive"""
            os.makedirs(os.path.dirname(local_path), exist_ok=True)
            request = service.files().get_media(fileId=file_id)
            with open(local_path, 'wb') as f:
                downloader = MediaIoBaseDownload(f, request)
                done = False
                while not done:
                    status, done = downloader.next_chunk()
        
        def upload_to_drive(local_path, parent_id, file_id=None):
            """Faz upload de arquivo para o Drive"""
            file_metadata = {'name': os.path.basename(local_path)}
            if not file_id:
                file_metadata['parents'] = [parent_id]
            
            media = MediaFileUpload(local_path, resumable=True)
            
            if file_id:
                # Atualizar arquivo existente
                return service.files().update(
                    fileId=file_id,
                    media_body=media
                ).execute()
            else:
                # Criar novo arquivo
                return service.files().create(
                    body=file_metadata,
                    media_body=media,
                    fields='id'
                ).execute()
        
        def ensure_drive_folder_structure(path, parent_id):
            """Garante que a estrutura de pastas existe no Drive"""
            parts = path.split('/')
            current_parent = parent_id
            
            for i, part in enumerate(parts[:-1]):
                folder_path = '/'.join(parts[:i+1])
                
                # Verificar se pasta existe
                query = f"name='{part}' and '{current_parent}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false"
                results = service.files().list(q=query, fields='files(id)').execute()
                
                if results.get('files'):
                    current_parent = results['files'][0]['id']
                else:
                    # Criar pasta
                    folder_metadata = {
                        'name': part,
                        'mimeType': 'application/vnd.google-apps.folder',
                        'parents': [current_parent]
                    }
                    folder = service.files().create(body=folder_metadata, fields='id').execute()
                    current_parent = folder['id']
            
            return current_parent
        
        def delete_from_drive(file_id):
            """Remove arquivo do Drive"""
            try:
                service.files().delete(fileId=file_id).execute()
                return True
            except:
                return False
        
        # Verificar pasta do reposit√≥rio no Drive
        print(f"\nüîç Verificando pasta do reposit√≥rio: {repo_name}")
        query = f"name='{repo_name}' and '{folder_id}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false"
        results = service.files().list(q=query, fields='files(id)').execute()
        
        if results.get('files'):
            repo_folder_id = results['files'][0]['id']
            print(f"üìÅ Pasta encontrada: {repo_name}")
        else:
            # Criar pasta do reposit√≥rio
            folder_metadata = {
                'name': repo_name,
                'mimeType': 'application/vnd.google-apps.folder',
                'parents': [folder_id]
            }
            folder = service.files().create(body=folder_metadata, fields='id').execute()
            repo_folder_id = folder['id']
            print(f"üìÅ Pasta criada: {repo_name}")
        
        # Carregar estado anterior
        sync_state = load_sync_state()
        previous_files = sync_state.get('files', {})
        
        # Obter arquivos atuais
        print("\nüìä Analisando arquivos...")
        local_files = get_local_files()
        drive_files = get_drive_files(repo_folder_id)
        
        print(f"  üìÇ Arquivos locais: {len(local_files)}")
        print(f"  ‚òÅÔ∏è Arquivos no Drive: {len(drive_files)}")
        
        # Detectar mudan√ßas
        changes = {
            'local_to_drive': [],  # Arquivos para enviar ao Drive
            'drive_to_local': [],  # Arquivos para baixar do Drive
            'conflicts': [],       # Arquivos modificados em ambos
            'delete_from_drive': [],  # Arquivos para deletar do Drive
            'delete_from_local': []   # Arquivos para deletar localmente
        }
        
        # Analisar cada arquivo
        all_paths = set(local_files.keys()) | set(drive_files.keys()) | set(previous_files.keys())
        
        for path in all_paths:
            in_local = path in local_files
            in_drive = path in drive_files
            in_previous = path in previous_files
            
            if in_local and in_drive:
                # Arquivo existe em ambos
                if local_files[path]['hash'] != drive_files[path]['hash']:
                    # Arquivo foi modificado
                    local_modified = parser.parse(local_files[path]['modified'])
                    drive_modified = parser.parse(drive_files[path]['modified'])
                    
                    if in_previous:
                        # Verificar qual foi modificado
                        if local_files[path]['hash'] != previous_files[path].get('local_hash'):
                            if drive_files[path]['hash'] != previous_files[path].get('drive_hash'):
                                # Ambos foram modificados - conflito
                                changes['conflicts'].append(path)
                            else:
                                # Apenas local foi modificado
                                changes['local_to_drive'].append(path)
                        elif drive_files[path]['hash'] != previous_files[path].get('drive_hash'):
                            # Apenas Drive foi modificado
                            changes['drive_to_local'].append(path)
                    else:
                        # Sem hist√≥rico, usar timestamp mais recente
                        if local_modified > drive_modified:
                            changes['local_to_drive'].append(path)
                        else:
                            changes['drive_to_local'].append(path)
            
            elif in_local and not in_drive:
                # Arquivo apenas local
                if in_previous and previous_files[path].get('drive_hash'):
                    # Foi deletado do Drive
                    changes['delete_from_local'].append(path)
                else:
                    # Novo arquivo local
                    changes['local_to_drive'].append(path)
            
            elif in_drive and not in_local:
                # Arquivo apenas no Drive
                if in_previous and previous_files[path].get('local_hash'):
                    # Foi deletado localmente
                    changes['delete_from_drive'].append(path)
                else:
                    # Novo arquivo no Drive
                    changes['drive_to_local'].append(path)
        
        # Mostrar resumo de mudan√ßas
        print("\nüìã Mudan√ßas detectadas:")
        print(f"  ‚¨ÜÔ∏è Local ‚Üí Drive: {len(changes['local_to_drive'])}")
        print(f"  ‚¨áÔ∏è Drive ‚Üí Local: {len(changes['drive_to_local'])}")
        print(f"  ‚ö†Ô∏è Conflitos: {len(changes['conflicts'])}")
        print(f"  üóëÔ∏è Deletar do Drive: {len(changes['delete_from_drive'])}")
        print(f"  üóëÔ∏è Deletar local: {len(changes['delete_from_local'])}")
        
        # Resolver conflitos (preferir vers√£o mais recente)
        for path in changes['conflicts']:
            local_modified = parser.parse(local_files[path]['modified'])
            drive_modified = parser.parse(drive_files[path]['modified'])
            
            if local_modified > drive_modified:
                changes['local_to_drive'].append(path)
                print(f"  ‚ö†Ô∏è Conflito em {path}: usando vers√£o local (mais recente)")
            else:
                changes['drive_to_local'].append(path)
                print(f"  ‚ö†Ô∏è Conflito em {path}: usando vers√£o do Drive (mais recente)")
        
        # Executar sincroniza√ß√£o
        total_changes = sum(len(changes[k]) for k in changes if k != 'conflicts')
        
        if total_changes == 0:
            print("\n‚úÖ Nenhuma mudan√ßa necess√°ria - tudo sincronizado!")
        else:
            print(f"\nüîÑ Executando {total_changes} opera√ß√µes de sincroniza√ß√£o...")
            
            # 1. Baixar arquivos do Drive
            for path in changes['drive_to_local']:
                print(f"  ‚¨áÔ∏è Baixando: {path}")
                try:
                    download_from_drive(drive_files[path]['id'], path)
                except Exception as e:
                    print(f"    ‚ùå Erro: {e}")
            
            # 2. Fazer upload para o Drive
            for path in changes['local_to_drive']:
                print(f"  ‚¨ÜÔ∏è Enviando: {path}")
                try:
                    parent_id = ensure_drive_folder_structure(path, repo_folder_id)
                    file_id = drive_files.get(path, {}).get('id')
                    upload_to_drive(path, parent_id, file_id)
                except Exception as e:
                    print(f"    ‚ùå Erro: {e}")
            
            # 3. Deletar do Drive
            for path in changes['delete_from_drive']:
                print(f"  üóëÔ∏è Deletando do Drive: {path}")
                try:
                    delete_from_drive(drive_files[path]['id'])
                except Exception as e:
                    print(f"    ‚ùå Erro: {e}")
            
            # 4. Deletar localmente
            for path in changes['delete_from_local']:
                print(f"  üóëÔ∏è Deletando local: {path}")
                try:
                    os.remove(path)
                except Exception as e:
                    print(f"    ‚ùå Erro: {e}")
            
            # Commit mudan√ßas se necess√°rio
            if changes['drive_to_local'] or changes['delete_from_local']:
                print("\nüìù Criando commit com mudan√ßas do Drive...")
                
                # Configurar git
                subprocess.run(['git', 'config', 'user.name', 'Sync Bot'], check=True)
                subprocess.run(['git', 'config', 'user.email', 'sync-bot@gad-pesquisa.bot'], check=True)
                
                # Adicionar mudan√ßas
                subprocess.run(['git', 'add', '-A'], check=True)
                
                # Criar mensagem de commit
                msg_parts = []
                if len(changes['drive_to_local']) > 0:
                    msg_parts.append(f"{len(changes['drive_to_local'])} arquivo(s) do Drive")
                if len(changes['delete_from_local']) > 0:
                    msg_parts.append(f"{len(changes['delete_from_local'])} arquivo(s) removido(s)")
                
                commit_message = f"[sync-bot] Sincroniza√ß√£o autom√°tica: {', '.join(msg_parts)}"
                
                # Fazer commit
                result = subprocess.run(['git', 'commit', '-m', commit_message], capture_output=True, text=True)
                
                if result.returncode == 0:
                    print("‚úÖ Commit criado com sucesso")
                    
                    # Push
                    push_result = subprocess.run(['git', 'push', 'origin', branch], capture_output=True, text=True)
                    if push_result.returncode == 0:
                        print("‚úÖ Push realizado com sucesso")
                    else:
                        print(f"‚ùå Erro no push: {push_result.stderr}")
            
            print("\n‚úÖ Sincroniza√ß√£o conclu√≠da!")
        
        # Salvar novo estado
        new_state = {
            'files': {},
            'last_sync': datetime.now(timezone.utc).isoformat()
        }
        
        # Atualizar estado com hashes atuais
        current_local = get_local_files()
        current_drive = get_drive_files(repo_folder_id)
        
        for path in set(current_local.keys()) | set(current_drive.keys()):
            new_state['files'][path] = {
                'local_hash': current_local.get(path, {}).get('hash'),
                'drive_hash': current_drive.get(path, {}).get('hash'),
                'local_modified': current_local.get(path, {}).get('modified'),
                'drive_modified': current_drive.get(path, {}).get('modified')
            }
        
        save_sync_state(new_state)
        
        # Atualizar hist√≥rico
        if total_changes > 0:
            print("\nüìã Atualizando hist√≥rico de sincroniza√ß√£o...")
            
            history_entry = f"\n## üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')} [Workflow Bidirecional]\n\n"
            history_entry += f"**Opera√ß√µes executadas:**\n"
            if changes['local_to_drive']:
                history_entry += f"- ‚¨ÜÔ∏è {len(changes['local_to_drive'])} arquivo(s) enviado(s) para o Drive\n"
            if changes['drive_to_local']:
                history_entry += f"- ‚¨áÔ∏è {len(changes['drive_to_local'])} arquivo(s) baixado(s) do Drive\n"
            if changes['delete_from_drive']:
                history_entry += f"- üóëÔ∏è {len(changes['delete_from_drive'])} arquivo(s) deletado(s) do Drive\n"
            if changes['delete_from_local']:
                history_entry += f"- üóëÔ∏è {len(changes['delete_from_local'])} arquivo(s) deletado(s) localmente\n"
            history_entry += "\n---\n"
            
            # Adicionar ao arquivo de hist√≥rico
            if os.path.exists(SYNC_HISTORY_FILE):
                with open(SYNC_HISTORY_FILE, 'r') as f:
                    current_history = f.read()
            else:
                current_history = "# üîÑ Hist√≥rico de Sincroniza√ß√£o\n\nSincroniza√ß√£o bidirecional autom√°tica entre GitHub e Google Drive.\n\n---\n"
            
            with open(SYNC_HISTORY_FILE, 'w') as f:
                f.write(current_history + history_entry)
        
        print("\n‚ú® Processo de sincroniza√ß√£o finalizado!")
        print(f"‚è∞ Pr√≥xima execu√ß√£o em 15 minutos ou no pr√≥ximo push")
        
        EOF
