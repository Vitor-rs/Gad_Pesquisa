name: Sync Repository to Google Drive (OAuth2)

on:
  push:
    branches: [ main, master ]
  workflow_dispatch:

jobs:
  sync-to-drive:
    runs-on: ubuntu-latest
    
    # PROTEÃ‡ÃƒO ANTI-LOOP: Pula execuÃ§Ã£o se o commit veio do Google Drive
    if: |
      !contains(github.event.head_commit.message, '[ğŸ—ƒï¸gdrive]') && 
      !contains(github.event.head_commit.message, '[skip ci]') &&
      !contains(github.event.head_commit.message, '[skip-ci]') &&
      github.event.head_commit.author.email != 'drive-sync@gad-pesquisa.bot'
    
    steps:
    - name: Log Sync Information
      run: |
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "ğŸ”„ SINCRONIZAÃ‡ÃƒO GITHUB â†’ GOOGLE DRIVE"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "ğŸ“ Mensagem do Commit: ${{ github.event.head_commit.message }}"
        echo "ğŸ‘¤ Autor: ${{ github.event.head_commit.author.name }} <${{ github.event.head_commit.author.email }}>"
        echo "ğŸ”— SHA: ${{ github.sha }}"
        echo "ğŸŒ¿ Branch: ${{ github.ref_name }}"
        echo "âœ… Este commit NÃƒO veio do Drive - SincronizaÃ§Ã£o autorizada"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        
    - name: Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # NecessÃ¡rio para obter histÃ³rico completo do git
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Sync to Google Drive
      env:
        # Adicionar uma flag para indicar que esta execuÃ§Ã£o veio do GitHub Actions
        SYNC_SOURCE: 'github-actions'
      run: |
        pip install google-api-python-client google-auth google-auth-oauthlib google-auth-httplib2 requests
        
        python << 'EOF'
        import os
        import sys
        import json
        import requests
        import subprocess
        from datetime import datetime
        from pathlib import Path
        from googleapiclient.discovery import build
        from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload
        from google.oauth2.credentials import Credentials
        import io
        import time
        
        print("ğŸ” Verificando credenciais OAuth2...")
        print("=" * 60)
        
        # ConfiguraÃ§Ãµes do repositÃ³rio - usando as mesmas variÃ¡veis do Colab
        repo_name = 'Gad_Pesquisa'  # NOME_REPO
        branch = 'main'  # BRANCH_PADRAO
        commit_sha = '${{ github.sha }}'
        folder_id = '${{ secrets.GOOGLE_DRIVE_FOLDER_ID }}'
        github_username = 'Vitor-rs'  # GITHUB_USERNAME
        github_email = 'vitor.santos9@estudante.ifms.edu.br'  # GITHUB_EMAIL
        
        # Credenciais OAuth2
        client_id = '${{ secrets.GOOGLE_CLIENT_ID }}'
        client_secret = '${{ secrets.GOOGLE_CLIENT_SECRET }}'
        refresh_token = '${{ secrets.GOOGLE_REFRESH_TOKEN }}'
        
        # Verificar se todas as credenciais estÃ£o presentes
        missing_secrets = []
        if not client_id: missing_secrets.append('GOOGLE_CLIENT_ID')
        if not client_secret: missing_secrets.append('GOOGLE_CLIENT_SECRET')
        if not refresh_token: missing_secrets.append('GOOGLE_REFRESH_TOKEN')
        if not folder_id: missing_secrets.append('GOOGLE_DRIVE_FOLDER_ID')
        
        if missing_secrets:
            print(f"âŒ ERRO: Secrets nÃ£o configurados: {', '.join(missing_secrets)}")
            sys.exit(1)
        
        print("âœ… Todas as credenciais encontradas!")
        print(f"ğŸ“ RepositÃ³rio: {repo_name}")
        print(f"ğŸ”€ Branch: {branch}")
        print(f"ğŸ“ Commit: {commit_sha[:8]}")
        print(f"ğŸ‘¤ UsuÃ¡rio: {github_username} <{github_email}>")
        
        # Obter informaÃ§Ãµes do commit usando git
        try:
            # Mensagem do commit
            commit_message = subprocess.check_output(
                ['git', 'log', '-1', '--pretty=%B', commit_sha],
                text=True
            ).strip()
            
            # Autor do commit
            commit_author = subprocess.check_output(
                ['git', 'log', '-1', '--pretty=%an <%ae>', commit_sha],
                text=True
            ).strip()
            
            # Data do commit
            commit_date = subprocess.check_output(
                ['git', 'log', '-1', '--pretty=%ai', commit_sha],
                text=True
            ).strip()
            
            # Arquivos modificados no commit
            changed_files = subprocess.check_output(
                ['git', 'diff-tree', '--no-commit-id', '--name-status', '-r', commit_sha],
                text=True
            ).strip().split('\n')
            
            # Processar lista de arquivos modificados
            files_info = []
            for file_line in changed_files:
                if file_line:
                    parts = file_line.split('\t')
                    if len(parts) >= 2:
                        status = parts[0]
                        filename = parts[1]
                        status_emoji = {
                            'A': 'â•',  # Adicionado
                            'M': 'ğŸ“',  # Modificado
                            'D': 'âŒ',  # Deletado
                            'R': 'ğŸ”„',  # Renomeado
                            'C': 'ğŸ“‹'   # Copiado
                        }.get(status[0], 'â“')
                        files_info.append(f"{status_emoji} {filename}")
            
        except Exception as e:
            print(f"âš ï¸ Aviso ao obter informaÃ§Ãµes do git: {e}")
            commit_message = "Mensagem nÃ£o disponÃ­vel"
            commit_author = f"{github_username} <{github_email}>"
            commit_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            files_info = ["InformaÃ§Ãµes de arquivos nÃ£o disponÃ­veis"]
        
        # Renovar access token usando refresh token
        print("\nğŸ”„ Renovando access token...")
        
        token_url = "https://oauth2.googleapis.com/token"
        token_data = {
            'client_id': client_id,
            'client_secret': client_secret,
            'refresh_token': refresh_token,
            'grant_type': 'refresh_token'
        }
        
        response = requests.post(token_url, data=token_data)
        
        if response.status_code != 200:
            print(f"âŒ Erro ao renovar token: {response.text}")
            sys.exit(1)
        
        token_info = response.json()
        access_token = token_info['access_token']
        
        print("âœ… Token renovado com sucesso!")
        
        # Criar credenciais para Google Drive API
        credentials = Credentials(
            token=access_token,
            refresh_token=refresh_token,
            token_uri="https://oauth2.googleapis.com/token",
            client_id=client_id,
            client_secret=client_secret,
            scopes=['https://www.googleapis.com/auth/drive']
        )
        
        # Conectar ao Google Drive
        service = build('drive', 'v3', credentials=credentials)
        
        # Testar conexÃ£o
        try:
            about = service.about().get(fields='user').execute()
            user_email = about.get('user', {}).get('emailAddress', 'Desconhecido')
            print(f"âœ… Conectado como: {user_email}")
        except Exception as e:
            print(f"âŒ Erro na conexÃ£o: {e}")
            sys.exit(1)
        
        # Verificar pasta de destino
        try:
            folder_info = service.files().get(fileId=folder_id).execute()
            print(f"ğŸ“ Pasta encontrada: {folder_info.get('name')}")
        except Exception as e:
            print(f"âŒ Pasta nÃ£o encontrada: {e}")
            sys.exit(1)
        
        # Criar arquivo de controle para evitar loops
        def create_sync_control_file(repo_folder_id):
            control_content = {
                "source": "github-actions",
                "timestamp": datetime.now().isoformat(),
                "commit_sha": commit_sha,
                "message": commit_message,
                "expires": (datetime.now().timestamp() + 300)  # 5 minutos
            }
            
            control_file_name = '.github_sync_control'
            
            # Verificar se arquivo jÃ¡ existe
            query = f"name='{control_file_name}' and '{repo_folder_id}' in parents and trashed=false"
            results = service.files().list(q=query, fields='files(id)').execute()
            existing_files = results.get('files', [])
            
            try:
                if existing_files:
                    # Atualizar arquivo existente
                    file_id = existing_files[0]['id']
                    media = MediaIoBaseUpload(
                        io.BytesIO(json.dumps(control_content).encode('utf-8')),
                        mimetype='application/json',
                        resumable=True
                    )
                    service.files().update(fileId=file_id, media_body=media).execute()
                else:
                    # Criar novo arquivo
                    file_metadata = {
                        'name': control_file_name,
                        'parents': [repo_folder_id],
                        'mimeType': 'application/json'
                    }
                    media = MediaIoBaseUpload(
                        io.BytesIO(json.dumps(control_content).encode('utf-8')),
                        mimetype='application/json',
                        resumable=True
                    )
                    service.files().create(body=file_metadata, media_body=media).execute()
                
                print(f"âœ… Arquivo de controle criado/atualizado")
            except Exception as e:
                print(f"âš ï¸ Erro ao criar arquivo de controle: {e}")
        
        # FunÃ§Ã£o para upload recursivo com proteÃ§Ã£o anti-loop
        def upload_directory(local_path, parent_id, path_prefix=""):
            uploaded_count = 0
            
            for item in sorted(os.listdir(local_path)):
                # Ignorar arquivos/pastas indesejados
                if item in ['.git', '__pycache__', 'node_modules', '.github']:
                    continue
                if item.startswith('.') and item not in ['.gitignore', '.env.example']:
                    continue
                
                item_path = os.path.join(local_path, item)
                drive_path = os.path.join(path_prefix, item) if path_prefix else item
                
                if os.path.isdir(item_path):
                    print(f"ğŸ“‚ Processando pasta: {drive_path}")
                    
                    # Verificar se pasta jÃ¡ existe
                    query = f"name='{item}' and '{parent_id}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false"
                    results = service.files().list(q=query, fields='files(id, name)').execute()
                    existing_folders = results.get('files', [])
                    
                    if existing_folders:
                        folder_id = existing_folders[0]['id']
                        print(f"  â™»ï¸  Pasta jÃ¡ existe, usando: {folder_id}")
                    else:
                        # Criar nova pasta
                        folder_metadata = {
                            'name': item,
                            'mimeType': 'application/vnd.google-apps.folder',
                            'parents': [parent_id]
                        }
                        folder = service.files().create(body=folder_metadata, fields='id').execute()
                        folder_id = folder.get('id')
                        print(f"  âœ… Pasta criada: {folder_id}")
                    
                    # Recursivamente fazer upload do conteÃºdo
                    uploaded_count += upload_directory(item_path, folder_id, drive_path)
                    
                else:
                    # Arquivo regular
                    file_size = os.path.getsize(item_path)
                    print(f"ğŸ“„ Arquivo: {drive_path} ({file_size:,} bytes)")
                    
                    # Verificar se arquivo jÃ¡ existe
                    query = f"name='{item}' and '{parent_id}' in parents and trashed=false"
                    results = service.files().list(q=query, fields='files(id, name)').execute()
                    existing_files = results.get('files', [])
                    
                    try:
                        if existing_files:
                            # Atualizar arquivo existente
                            file_id = existing_files[0]['id']
                            media = MediaFileUpload(item_path, resumable=True)
                            service.files().update(fileId=file_id, media_body=media).execute()
                            print(f"  â™»ï¸  Atualizado")
                        else:
                            # Criar novo arquivo
                            file_metadata = {
                                'name': item,
                                'parents': [parent_id]
                            }
                            media = MediaFileUpload(item_path, resumable=True)
                            service.files().create(body=file_metadata, media_body=media, fields='id').execute()
                            print(f"  âœ… Enviado")
                        
                        uploaded_count += 1
                    except Exception as e:
                        print(f"  âŒ Erro: {e}")
            
            return uploaded_count
        
        # Verificar se pasta do repositÃ³rio jÃ¡ existe
        print(f"\nğŸ” Verificando pasta do repositÃ³rio: {repo_name}")
        
        query = f"name='{repo_name}' and '{folder_id}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false"
        results = service.files().list(q=query, fields='files(id, name)').execute()
        repo_folders = results.get('files', [])
        
        if repo_folders:
            repo_folder_id = repo_folders[0]['id']
            print(f"ğŸ“ Pasta encontrada: {repo_name} (ID: {repo_folder_id})")
            
            # Criar arquivo de controle ANTES de limpar
            create_sync_control_file(repo_folder_id)
            
            # Aguardar um momento para garantir que o arquivo foi criado
            time.sleep(2)
            
            # Limpar conteÃºdo existente (exceto arquivos de controle)
            print("ğŸ§¹ Limpando conteÃºdo anterior...")
            query = f"'{repo_folder_id}' in parents and trashed=false"
            results = service.files().list(q=query, fields='files(id, name)').execute()
            files_to_delete = results.get('files', [])
            
            history_file_id = None
            for file in files_to_delete:
                # Preservar arquivos importantes
                if file['name'] in ['_SYNC_HISTORY.md', '.github_sync_control', '.last_sync_from_github']:
                    if file['name'] == '_SYNC_HISTORY.md':
                        history_file_id = file['id']
                    print(f"  ğŸ“‹ Mantendo: {file['name']}")
                else:
                    try:
                        service.files().delete(fileId=file['id']).execute()
                        print(f"  ğŸ—‘ï¸  Removido: {file['name']}")
                    except:
                        pass
        else:
            # Criar nova pasta
            print(f"ğŸ“ Criando pasta: {repo_name}")
            
            folder_metadata = {
                'name': repo_name,
                'mimeType': 'application/vnd.google-apps.folder',
                'parents': [folder_id]
            }
            
            folder = service.files().create(
                body=folder_metadata,
                fields='id'
            ).execute()
            
            repo_folder_id = folder.get('id')
            history_file_id = None
            
            # Criar arquivo de controle na nova pasta
            create_sync_control_file(repo_folder_id)
        
        # Preparar nova entrada do histÃ³rico
        sync_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')
        new_entry = f"\n## ğŸ“… {sync_time} [GitHub Actions]\n\n"
        new_entry += f"**Commit:** `{commit_sha[:8]}` - {commit_message}\n\n"
        new_entry += f"**Autor:** {commit_author}\n\n"
        new_entry += f"**Data do Commit:** {commit_date}\n\n"
        new_entry += f"**Branch:** `{branch}`\n\n"
        new_entry += f"**Conta de SincronizaÃ§Ã£o:** {user_email}\n\n"
        new_entry += f"**Origem:** GitHub Actions â†’ Google Drive\n\n"
        
        if files_info:
            new_entry += "### ğŸ“‹ Arquivos Modificados:\n\n"
            for file_info in files_info:
                new_entry += f"- {file_info}\n"
        
        new_entry += "\n---\n"
        
        # Buscar histÃ³rico existente ou criar novo
        existing_history = ""
        if history_file_id:
            try:
                # Baixar arquivo existente
                request = service.files().get_media(fileId=history_file_id)
                file_handle = io.BytesIO()
                downloader = MediaIoBaseDownload(file_handle, request)
                done = False
                while not done:
                    status, done = downloader.next_chunk()
                
                file_handle.seek(0)
                existing_history = file_handle.read().decode('utf-8')
                print("ğŸ“‹ HistÃ³rico existente carregado")
            except Exception as e:
                print(f"âš ï¸ NÃ£o foi possÃ­vel carregar histÃ³rico existente: {e}")
        
        # Se nÃ£o existe histÃ³rico, criar cabeÃ§alho
        if not existing_history:
            existing_history = "# ğŸ”„ HistÃ³rico de SincronizaÃ§Ã£o\n\n"
            existing_history += f"Este arquivo mantÃ©m um registro histÃ³rico de todas as sincronizaÃ§Ãµes do repositÃ³rio **{repo_name}** com o Google Drive.\n\n"
            existing_history += "---\n"
        
        # Adicionar nova entrada ao histÃ³rico
        updated_history = existing_history + new_entry
        
        # Salvar histÃ³rico atualizado
        with open('_SYNC_HISTORY.md', 'w', encoding='utf-8') as f:
            f.write(updated_history)
        
        # Fazer upload de todos os arquivos
        print("\nğŸ“¤ Sincronizando arquivos...")
        total_uploaded = upload_directory('.', repo_folder_id)
        
        print(f"\nğŸ‰ SincronizaÃ§Ã£o concluÃ­da com sucesso!")
        print("=" * 50)
        print(f"ğŸ“ RepositÃ³rio: {repo_name}")
        print(f"ğŸ”€ Branch: {branch}")
        print(f"ğŸ“ Commit: {commit_sha[:8]} - {commit_message}")
        print(f"ğŸ“Š Arquivos processados: {total_uploaded}")
        print(f"ğŸ‘¤ Conta: {user_email}")
        print(f"â° HorÃ¡rio: {sync_time}")
        print("=" * 50)
        print("âœ¨ SincronizaÃ§Ã£o usando conta institucional concluÃ­da!")
        print("ğŸ“‹ HistÃ³rico atualizado em _SYNC_HISTORY.md")
        print("ğŸ›¡ï¸ Arquivo de controle criado para evitar loops")
        
        EOF
